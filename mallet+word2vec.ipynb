{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine LDA and locally created word2vec library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import aira_processor_dict as apd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in an AiraProcessor instance and extract the corpus from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = apd.AiraProcessor(part_of_speech='all', process_type='asis', min_occurrences=25)\n",
    "with open('aira_processor_instances/' + ap.output_file_name() + '.p', 'rb') as file:\n",
    "    ap = pickle.load(file)\n",
    "    \n",
    "texts = ap.output_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a local word2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_word=100\n",
    "model_wv=word2vec.Word2Vec(texts, size=size_word,workers=2,min_count=1,iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Mallet LDA model (creating Dictionary and id corpus first). Then convert to a gensim lda model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.rsm-msba/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(texts)\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "np.random.seed(100)\n",
    "size_lda = 14\n",
    "mallet_path = 'mallet-2.0.8/mallet-2.0.8/bin/mallet' \n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=size_lda, id2word=id2word)\n",
    "\n",
    "# transform mallet to lda\n",
    "lda = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(ldamallet, gamma_threshold=0.001, iterations=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the weight of each word in the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_id=[]\n",
    "the_vl=[]\n",
    "the_w =[]\n",
    "\n",
    "for x in range(size_lda):\n",
    "    the_id.append([xx[0] for xx in lda.get_topic_terms(x,topn=5)])\n",
    "    the_sum=sum([xx[1] for xx in lda.get_topic_terms(x,topn=5)])\n",
    "    the_w.append([xx[1]/the_sum for xx in lda.get_topic_terms(x,topn=5)])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the topic to the word2vec space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Mapping the topic to the word2vec space\n",
    "m=0\n",
    "the_wv=np.zeros([size_lda,size_word])\n",
    "\n",
    "for it in the_id:\n",
    "    n=0\n",
    "    for it_id in it:\n",
    "        word_t=id2word[it_id]\n",
    "        #print (word_t+\"**\",np.shape(model_wv[word_t]),the_w[m][n])\n",
    "        the_wv[m]+=[x_word*the_w[m][n] for x_word in model_wv[word_t]]\n",
    "        n+=1\n",
    "    m+=1\n",
    "doc_word=np.zeros([len(texts),size_word])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the documents to the word2vec space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Mapping the document to the word2vec space\n",
    "m=0\n",
    "for each_doc in texts:\n",
    "    for each_word in each_doc:\n",
    "        #print each_word\n",
    "        doc_word[m]+=model_wv[each_word]\n",
    "    n=0\n",
    "    for doc_word_each in doc_word[m]:\n",
    "        doc_word[m][n]=doc_word[m][n]/len(doc_word[m])\n",
    "        n+=1\n",
    "    m+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the distance between each document each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destince(a,b):\n",
    "    dt=0\n",
    "    for each_dt in range(len(a)):\n",
    "        dt+=(a[each_dt]-b[each_dt])*(a[each_dt]-b[each_dt])\n",
    "    return np.sqrt(dt)\n",
    "doc_t=np.zeros([len(doc_word),size_lda])\n",
    "m=0\n",
    "for each_d in doc_word:\n",
    "    n=0\n",
    "    for each_t in the_wv:\n",
    "        doc_t[m][n]=destince(each_d,each_t)\n",
    "        n+=1\n",
    "    m+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the nearest topic to a document its dominant topic and then count the results. The challenge we were having with combining word2vec and LDA was that it concentrates the documents in one topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({10: 5536, 2: 950, 1: 320, 6: 125, 4: 99, 11: 59, 8: 49, 3: 49, 0: 32, 5: 16, 7: 8, 12: 5, 9: 5, 13: 4})\n"
     ]
    }
   ],
   "source": [
    "topic = [np.argmin(i) for i in doc_t]\n",
    "\n",
    "print(Counter(topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
